{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 21978006.0\n",
      "loss: 17160970.0\n",
      "loss: 15565965.0\n",
      "loss: 15153887.0\n",
      "loss: 14800799.0\n",
      "loss: 13774505.0\n",
      "loss: 11909844.0\n",
      "loss: 9470506.0\n",
      "loss: 7004527.5\n",
      "loss: 4903612.5\n",
      "loss: 3334817.0\n",
      "loss: 2254034.5\n",
      "loss: 1546523.125\n",
      "loss: 1091952.5\n",
      "loss: 800153.375\n",
      "loss: 609918.4375\n",
      "loss: 482512.84375\n",
      "loss: 394206.8125\n",
      "loss: 330631.96875\n",
      "loss: 283118.4375\n",
      "loss: 246325.09375\n",
      "loss: 216859.9375\n",
      "loss: 192637.125\n",
      "loss: 172302.3125\n",
      "loss: 154946.59375\n",
      "loss: 139944.59375\n",
      "loss: 126877.0390625\n",
      "loss: 115395.453125\n",
      "loss: 105237.703125\n",
      "loss: 96206.1015625\n",
      "loss: 88152.4609375\n",
      "loss: 80936.65625\n",
      "loss: 74450.15625\n",
      "loss: 68604.375\n",
      "loss: 63318.6484375\n",
      "loss: 58527.32421875\n",
      "loss: 54175.4140625\n",
      "loss: 50210.75\n",
      "loss: 46595.046875\n",
      "loss: 43290.68359375\n",
      "loss: 40266.16015625\n",
      "loss: 37493.81640625\n",
      "loss: 34947.8046875\n",
      "loss: 32606.16015625\n",
      "loss: 30453.09375\n",
      "loss: 28467.662109375\n",
      "loss: 26635.326171875\n",
      "loss: 24941.453125\n",
      "loss: 23373.10546875\n",
      "loss: 21919.962890625\n",
      "loss: 20571.65625\n",
      "loss: 19319.6015625\n",
      "loss: 18155.71875\n",
      "loss: 17072.11328125\n",
      "loss: 16064.3212890625\n",
      "loss: 15125.28125\n",
      "loss: 14249.09765625\n",
      "loss: 13431.6044921875\n",
      "loss: 12667.9921875\n",
      "loss: 11953.83984375\n",
      "loss: 11285.73046875\n",
      "loss: 10659.8828125\n",
      "loss: 10075.404296875\n",
      "loss: 9528.32421875\n",
      "loss: 9015.259765625\n",
      "loss: 8533.751953125\n",
      "loss: 8081.4150390625\n",
      "loss: 7656.076171875\n",
      "loss: 7255.7822265625\n",
      "loss: 6879.1005859375\n",
      "loss: 6524.23828125\n",
      "loss: 6189.91162109375\n",
      "loss: 5874.7783203125\n",
      "loss: 5577.5361328125\n",
      "loss: 5296.9775390625\n",
      "loss: 5032.09130859375\n",
      "loss: 4781.974609375\n",
      "loss: 4545.58251953125\n",
      "loss: 4322.15673828125\n",
      "loss: 4110.916015625\n",
      "loss: 3911.132080078125\n",
      "loss: 3722.007568359375\n",
      "loss: 3542.93359375\n",
      "loss: 3373.360107421875\n",
      "loss: 3212.779296875\n",
      "loss: 3060.52783203125\n",
      "loss: 2916.181640625\n",
      "loss: 2779.351806640625\n",
      "loss: 2649.52685546875\n",
      "loss: 2526.331298828125\n",
      "loss: 2409.380859375\n",
      "loss: 2298.37451171875\n",
      "loss: 2192.92578125\n",
      "loss: 2092.71728515625\n",
      "loss: 1997.484375\n",
      "loss: 1906.9720458984375\n",
      "loss: 1820.93798828125\n",
      "loss: 1739.1197509765625\n",
      "loss: 1661.291259765625\n",
      "loss: 1587.239990234375\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1')\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "w1 = torch.randn(D_in, H, device=device)\n",
    "w2 = torch.randn(H, D_out, device=device)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(100):\n",
    "    h = torch.mm(x, w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = torch.mm(h_relu, w2)\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    \n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "    \n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "    print(f'loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26383264.0\n",
      "loss: 23374048.0\n",
      "loss: 22172578.0\n",
      "loss: 20245908.0\n",
      "loss: 16807852.0\n",
      "loss: 12394112.0\n",
      "loss: 8291273.0\n",
      "loss: 5207058.0\n",
      "loss: 3230930.0\n",
      "loss: 2056731.125\n",
      "loss: 1380562.75\n",
      "loss: 984913.75\n",
      "loss: 744018.75\n",
      "loss: 588351.375\n",
      "loss: 481171.71875\n",
      "loss: 402890.25\n",
      "loss: 342853.75\n",
      "loss: 295199.96875\n",
      "loss: 256351.5\n",
      "loss: 224074.8125\n",
      "loss: 196902.59375\n",
      "loss: 173801.140625\n",
      "loss: 154012.125\n",
      "loss: 136969.71875\n",
      "loss: 122217.640625\n",
      "loss: 109402.25\n",
      "loss: 98213.796875\n",
      "loss: 88399.203125\n",
      "loss: 79756.71875\n",
      "loss: 72125.5234375\n",
      "loss: 65369.5625\n",
      "loss: 59368.3125\n",
      "loss: 54021.609375\n",
      "loss: 49236.0\n",
      "loss: 44954.796875\n",
      "loss: 41112.984375\n",
      "loss: 37657.1328125\n",
      "loss: 34543.62109375\n",
      "loss: 31735.6875\n",
      "loss: 29193.86328125\n",
      "loss: 26888.640625\n",
      "loss: 24794.09765625\n",
      "loss: 22889.8125\n",
      "loss: 21153.642578125\n",
      "loss: 19568.0625\n",
      "loss: 18118.12109375\n",
      "loss: 16790.08203125\n",
      "loss: 15572.47265625\n",
      "loss: 14454.443359375\n",
      "loss: 13426.71484375\n",
      "loss: 12481.5654296875\n",
      "loss: 11612.591796875\n",
      "loss: 10810.849609375\n",
      "loss: 10070.583984375\n",
      "loss: 9386.51171875\n",
      "loss: 8753.6328125\n",
      "loss: 8167.7744140625\n",
      "loss: 7624.921875\n",
      "loss: 7121.6259765625\n",
      "loss: 6654.70556640625\n",
      "loss: 6221.1181640625\n",
      "loss: 5818.240234375\n",
      "loss: 5443.66943359375\n",
      "loss: 5095.1748046875\n",
      "loss: 4770.6083984375\n",
      "loss: 4468.27783203125\n",
      "loss: 4186.6416015625\n",
      "loss: 3924.206787109375\n",
      "loss: 3679.399169921875\n",
      "loss: 3450.871337890625\n",
      "loss: 3237.56787109375\n",
      "loss: 3038.3134765625\n",
      "loss: 2852.089599609375\n",
      "loss: 2678.0146484375\n",
      "loss: 2515.21533203125\n",
      "loss: 2362.88720703125\n",
      "loss: 2220.35693359375\n",
      "loss: 2086.94873046875\n",
      "loss: 1961.930908203125\n",
      "loss: 1844.8387451171875\n",
      "loss: 1735.10791015625\n",
      "loss: 1632.2265625\n",
      "loss: 1535.8216552734375\n",
      "loss: 1445.3944091796875\n",
      "loss: 1360.552734375\n",
      "loss: 1280.940673828125\n",
      "loss: 1206.2392578125\n",
      "loss: 1136.075927734375\n",
      "loss: 1070.1697998046875\n",
      "loss: 1008.2584838867188\n",
      "loss: 950.084228515625\n",
      "loss: 895.406982421875\n",
      "loss: 844.0147094726562\n",
      "loss: 795.6884765625\n",
      "loss: 750.2453002929688\n",
      "loss: 707.524658203125\n",
      "loss: 667.309326171875\n",
      "loss: 629.4685668945312\n",
      "loss: 593.8636474609375\n",
      "loss: 560.3491821289062\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1')\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "w1 = torch.randn(D_in, H, device=device, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(100):\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():    \n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()\n",
    "    print(f'loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
