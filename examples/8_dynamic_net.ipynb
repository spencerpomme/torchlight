{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: Control Flow + Weight Sharing\n",
    "--------------------------------------\n",
    "\n",
    "To showcase the power of PyTorch dynamic graphs, we will implement a very strange\n",
    "model: a fully-connected ReLU network that on each forward pass randomly chooses\n",
    "a number between 1 and 4 and has that many hidden layers, reusing the same\n",
    "weights multiple times to compute the innermost hidden layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 632.0070190429688\n",
      "1 666.876953125\n",
      "2 638.161865234375\n",
      "3 627.4966430664062\n",
      "4 540.6419677734375\n",
      "5 625.9701538085938\n",
      "6 624.4487915039062\n",
      "7 404.8503112792969\n",
      "8 360.1130676269531\n",
      "9 309.9834899902344\n",
      "10 619.8305053710938\n",
      "11 617.7686767578125\n",
      "12 187.36077880859375\n",
      "13 619.4473266601562\n",
      "14 572.4185180664062\n",
      "15 560.6989135742188\n",
      "16 538.2614135742188\n",
      "17 615.2755737304688\n",
      "18 478.0504150390625\n",
      "19 91.02987670898438\n",
      "20 607.3973999023438\n",
      "21 86.8807601928711\n",
      "22 599.2420654296875\n",
      "23 593.2177734375\n",
      "24 541.4122314453125\n",
      "25 524.780029296875\n",
      "26 298.0304870605469\n",
      "27 274.3638610839844\n",
      "28 451.6155700683594\n",
      "29 420.3275146484375\n",
      "30 474.326904296875\n",
      "31 193.68658447265625\n",
      "32 415.274169921875\n",
      "33 304.5037841796875\n",
      "34 279.4242248535156\n",
      "35 328.88238525390625\n",
      "36 199.12786865234375\n",
      "37 211.66763305664062\n",
      "38 162.36727905273438\n",
      "39 164.17698669433594\n",
      "40 220.40512084960938\n",
      "41 192.2908477783203\n",
      "42 318.90118408203125\n",
      "43 120.50137329101562\n",
      "44 150.4662322998047\n",
      "45 110.84688568115234\n",
      "46 141.32614135742188\n",
      "47 106.79881286621094\n",
      "48 193.39822387695312\n",
      "49 93.61613464355469\n",
      "50 111.62785339355469\n",
      "51 333.3445739746094\n",
      "52 120.41731262207031\n",
      "53 355.3976135253906\n",
      "54 121.08744812011719\n",
      "55 97.92630004882812\n",
      "56 69.42066955566406\n",
      "57 132.80569458007812\n",
      "58 307.2193603515625\n",
      "59 179.01666259765625\n",
      "60 198.1381378173828\n",
      "61 111.98760986328125\n",
      "62 141.33401489257812\n",
      "63 124.67630767822266\n",
      "64 105.47520446777344\n",
      "65 71.84626770019531\n",
      "66 66.71626281738281\n",
      "67 71.02140808105469\n",
      "68 112.6629409790039\n",
      "69 57.88846206665039\n",
      "70 67.67723846435547\n",
      "71 60.258216857910156\n",
      "72 94.04749298095703\n",
      "73 38.970340728759766\n",
      "74 33.11956787109375\n",
      "75 55.87410354614258\n",
      "76 50.117008209228516\n",
      "77 27.598541259765625\n",
      "78 39.0374755859375\n",
      "79 50.73560333251953\n",
      "80 54.709068298339844\n",
      "81 29.80046844482422\n",
      "82 46.67079162597656\n",
      "83 67.47447204589844\n",
      "84 18.03594207763672\n",
      "85 39.91324234008789\n",
      "86 16.593151092529297\n",
      "87 26.35077667236328\n",
      "88 49.056968688964844\n",
      "89 18.984359741210938\n",
      "90 16.799501419067383\n",
      "91 19.188390731811523\n",
      "92 16.746328353881836\n",
      "93 20.54315185546875\n",
      "94 86.32504272460938\n",
      "95 17.032392501831055\n",
      "96 16.839929580688477\n",
      "97 18.93947982788086\n",
      "98 38.53049087524414\n",
      "99 32.120460510253906\n",
      "100 49.7581787109375\n",
      "101 12.125391960144043\n",
      "102 14.938220024108887\n",
      "103 32.001041412353516\n",
      "104 24.864683151245117\n",
      "105 25.24068832397461\n",
      "106 14.2750883102417\n",
      "107 12.770772933959961\n",
      "108 9.29539680480957\n",
      "109 11.791711807250977\n",
      "110 9.049995422363281\n",
      "111 9.330495834350586\n",
      "112 6.829131126403809\n",
      "113 9.34477710723877\n",
      "114 5.673237323760986\n",
      "115 3.5887672901153564\n",
      "116 11.034912109375\n",
      "117 8.116598129272461\n",
      "118 6.358736991882324\n",
      "119 4.281466484069824\n",
      "120 18.87371826171875\n",
      "121 3.822028636932373\n",
      "122 17.059301376342773\n",
      "123 12.703006744384766\n",
      "124 3.8391518592834473\n",
      "125 9.118583679199219\n",
      "126 8.146163940429688\n",
      "127 7.810518741607666\n",
      "128 5.3823723793029785\n",
      "129 6.094701766967773\n",
      "130 5.288153648376465\n",
      "131 10.844016075134277\n",
      "132 7.182336330413818\n",
      "133 3.8384809494018555\n",
      "134 6.550644397735596\n",
      "135 15.879789352416992\n",
      "136 2.43424916267395\n",
      "137 4.491299629211426\n",
      "138 2.818523406982422\n",
      "139 2.79247784614563\n",
      "140 2.2970497608184814\n",
      "141 10.069903373718262\n",
      "142 1.1934762001037598\n",
      "143 4.654748916625977\n",
      "144 5.303057670593262\n",
      "145 5.582021236419678\n",
      "146 4.486295223236084\n",
      "147 4.531087875366211\n",
      "148 2.3124964237213135\n",
      "149 1.8251712322235107\n",
      "150 1.2330706119537354\n",
      "151 11.7347993850708\n",
      "152 0.612940788269043\n",
      "153 0.500311553478241\n",
      "154 4.164840221405029\n",
      "155 3.465996265411377\n",
      "156 4.692912578582764\n",
      "157 1.531335473060608\n",
      "158 4.617856025695801\n",
      "159 3.5210776329040527\n",
      "160 0.9115548729896545\n",
      "161 3.1401052474975586\n",
      "162 3.241485595703125\n",
      "163 3.809558868408203\n",
      "164 1.9249823093414307\n",
      "165 2.404907703399658\n",
      "166 3.963569164276123\n",
      "167 1.4765580892562866\n",
      "168 1.2320369482040405\n",
      "169 3.5788445472717285\n",
      "170 1.4094133377075195\n",
      "171 7.9644575119018555\n",
      "172 3.048917770385742\n",
      "173 1.135745882987976\n",
      "174 4.785563945770264\n",
      "175 3.8133749961853027\n",
      "176 2.281169891357422\n",
      "177 1.9632105827331543\n",
      "178 2.559147357940674\n",
      "179 3.3807520866394043\n",
      "180 4.81566858291626\n",
      "181 0.8118180632591248\n",
      "182 4.5747222900390625\n",
      "183 1.2844998836517334\n",
      "184 0.9583494067192078\n",
      "185 0.580572247505188\n",
      "186 12.469681739807129\n",
      "187 1.2259085178375244\n",
      "188 3.58229398727417\n",
      "189 3.7980659008026123\n",
      "190 5.004620552062988\n",
      "191 4.165811061859131\n",
      "192 2.187669038772583\n",
      "193 1.6970939636230469\n",
      "194 3.467607021331787\n",
      "195 3.7820169925689697\n",
      "196 1.0929185152053833\n",
      "197 2.5640506744384766\n",
      "198 2.5971519947052\n",
      "199 0.5200503468513489\n",
      "200 3.116554021835327\n",
      "201 0.42810627818107605\n",
      "202 0.3284839689731598\n",
      "203 1.3750245571136475\n",
      "204 2.462754964828491\n",
      "205 0.24202914535999298\n",
      "206 1.668493628501892\n",
      "207 0.3437339663505554\n",
      "208 1.5340548753738403\n",
      "209 1.46541166305542\n",
      "210 0.24338743090629578\n",
      "211 0.2397741675376892\n",
      "212 1.378961205482483\n",
      "213 0.24924258887767792\n",
      "214 1.8823089599609375\n",
      "215 0.8268883228302002\n",
      "216 0.19117438793182373\n",
      "217 1.5901309251785278\n",
      "218 1.4642813205718994\n",
      "219 0.2829321622848511\n",
      "220 2.424194812774658\n",
      "221 0.7056341767311096\n",
      "222 0.8786255717277527\n",
      "223 0.840890645980835\n",
      "224 0.464354932308197\n",
      "225 2.4353456497192383\n",
      "226 0.9606679677963257\n",
      "227 0.34697526693344116\n",
      "228 0.8133239150047302\n",
      "229 0.8617657423019409\n",
      "230 1.1230387687683105\n",
      "231 0.6158028244972229\n",
      "232 0.7305749654769897\n",
      "233 2.1416022777557373\n",
      "234 0.802925169467926\n",
      "235 0.7902448177337646\n",
      "236 0.4189998209476471\n",
      "237 0.548311710357666\n",
      "238 0.2712108790874481\n",
      "239 0.2431412786245346\n",
      "240 0.8127603530883789\n",
      "241 0.1969476044178009\n",
      "242 0.4502621293067932\n",
      "243 2.2838642597198486\n",
      "244 1.058288335800171\n",
      "245 1.1939125061035156\n",
      "246 2.4118144512176514\n",
      "247 0.6348966360092163\n",
      "248 1.6599303483963013\n",
      "249 0.20555061101913452\n",
      "250 0.2450292408466339\n",
      "251 1.2745399475097656\n",
      "252 1.7385674715042114\n",
      "253 0.9433590769767761\n",
      "254 0.2508942186832428\n",
      "255 3.192018508911133\n",
      "256 0.2083025723695755\n",
      "257 0.9172039031982422\n",
      "258 0.9366050362586975\n",
      "259 1.126284122467041\n",
      "260 0.22878538072109222\n",
      "261 0.21318671107292175\n",
      "262 0.6458938717842102\n",
      "263 1.135767936706543\n",
      "264 1.8773900270462036\n",
      "265 0.5767357349395752\n",
      "266 1.1609232425689697\n",
      "267 0.38856276869773865\n",
      "268 0.28760528564453125\n",
      "269 0.18342545628547668\n",
      "270 1.9897229671478271\n",
      "271 0.7242296934127808\n",
      "272 1.334932804107666\n",
      "273 0.21591049432754517\n",
      "274 1.5339716672897339\n",
      "275 1.1206156015396118\n",
      "276 0.2860221266746521\n",
      "277 1.222509503364563\n",
      "278 0.28673940896987915\n",
      "279 1.5560777187347412\n",
      "280 1.0701261758804321\n",
      "281 0.8043637275695801\n",
      "282 0.2707268297672272\n",
      "283 0.29488086700439453\n",
      "284 1.5934312343597412\n",
      "285 0.13585606217384338\n",
      "286 1.1671544313430786\n",
      "287 0.1461072862148285\n",
      "288 0.8747367858886719\n",
      "289 0.8980740308761597\n",
      "290 0.36658400297164917\n",
      "291 1.0956600904464722\n",
      "292 1.4341681003570557\n",
      "293 0.08629482984542847\n",
      "294 1.2934439182281494\n",
      "295 0.9560124278068542\n",
      "296 1.02978515625\n",
      "297 0.669114887714386\n",
      "298 1.0128952264785767\n",
      "299 0.9457321166992188\n",
      "300 1.0857917070388794\n",
      "301 0.6770318150520325\n",
      "302 0.7552151679992676\n",
      "303 0.6118913888931274\n",
      "304 1.1753671169281006\n",
      "305 0.8751628994941711\n",
      "306 0.3203275203704834\n",
      "307 1.0522955656051636\n",
      "308 0.7063104510307312\n",
      "309 0.5778277516365051\n",
      "310 0.8006033301353455\n",
      "311 0.68680340051651\n",
      "312 0.6135430932044983\n",
      "313 0.7263984680175781\n",
      "314 0.6987455487251282\n",
      "315 0.5767401456832886\n",
      "316 0.4582894444465637\n",
      "317 0.3653910160064697\n",
      "318 3.2666873931884766\n",
      "319 0.44398409128189087\n",
      "320 1.3317646980285645\n",
      "321 0.6143879890441895\n",
      "322 1.2987810373306274\n",
      "323 0.19593076407909393\n",
      "324 0.49782171845436096\n",
      "325 0.2614764869213104\n",
      "326 1.3458653688430786\n",
      "327 0.7011097073554993\n",
      "328 0.44266006350517273\n",
      "329 0.36612316966056824\n",
      "330 0.2130512297153473\n",
      "331 1.4244961738586426\n",
      "332 0.5848292708396912\n",
      "333 0.8266287446022034\n",
      "334 0.4950701594352722\n",
      "335 1.0307568311691284\n",
      "336 0.7235549688339233\n",
      "337 0.631608784198761\n",
      "338 0.5940181612968445\n",
      "339 0.3223087191581726\n",
      "340 1.3995383977890015\n",
      "341 0.18987706303596497\n",
      "342 0.12625446915626526\n",
      "343 0.5979681611061096\n",
      "344 0.8907189965248108\n",
      "345 0.693969190120697\n",
      "346 0.5849440693855286\n",
      "347 0.5438969135284424\n",
      "348 0.2145635187625885\n",
      "349 0.18398350477218628\n",
      "350 1.9258733987808228\n",
      "351 0.1176765039563179\n",
      "352 0.456241250038147\n",
      "353 0.7066180109977722\n",
      "354 0.7766666412353516\n",
      "355 0.5282367467880249\n",
      "356 0.31602683663368225\n",
      "357 1.0282411575317383\n",
      "358 0.5229739546775818\n",
      "359 0.2257373183965683\n",
      "360 0.19039712846279144\n",
      "361 0.5819891095161438\n",
      "362 0.0949435606598854\n",
      "363 0.4980326294898987\n",
      "364 0.11337604373693466\n",
      "365 1.6787134408950806\n",
      "366 0.29495781660079956\n",
      "367 0.920957088470459\n",
      "368 0.6860498189926147\n",
      "369 0.891757071018219\n",
      "370 0.43072277307510376\n",
      "371 0.5235958099365234\n",
      "372 1.1451621055603027\n",
      "373 0.5039417743682861\n",
      "374 0.4665279984474182\n",
      "375 0.5103418231010437\n",
      "376 1.0064982175827026\n",
      "377 0.1388522833585739\n",
      "378 0.3477901518344879\n",
      "379 0.15724219381809235\n",
      "380 0.3829500675201416\n",
      "381 0.5010614991188049\n",
      "382 0.2547187805175781\n",
      "383 0.4324892461299896\n",
      "384 0.9345386028289795\n",
      "385 0.11236171424388885\n",
      "386 0.36810141801834106\n",
      "387 0.11401037126779556\n",
      "388 0.843342661857605\n",
      "389 0.7729241251945496\n",
      "390 0.6795130968093872\n",
      "391 0.5733910202980042\n",
      "392 0.4281509220600128\n",
      "393 0.09490698575973511\n",
      "394 0.7627187967300415\n",
      "395 0.1111425906419754\n",
      "396 0.10584083199501038\n",
      "397 0.6711167693138123\n",
      "398 0.3818025588989258\n",
      "399 0.5060768723487854\n",
      "400 0.38465452194213867\n",
      "401 0.503559947013855\n",
      "402 0.447483092546463\n",
      "403 0.3685433864593506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 0.10278981178998947\n",
      "405 0.5079350471496582\n",
      "406 0.2549491226673126\n",
      "407 0.135505810379982\n",
      "408 0.8293576240539551\n",
      "409 0.7672693133354187\n",
      "410 0.11015011370182037\n",
      "411 0.6788011789321899\n",
      "412 0.3940145671367645\n",
      "413 0.050739821046590805\n",
      "414 0.5166071653366089\n",
      "415 0.566130518913269\n",
      "416 0.043732915073633194\n",
      "417 0.37018921971321106\n",
      "418 0.04540588706731796\n",
      "419 0.47056618332862854\n",
      "420 0.045646168291568756\n",
      "421 0.6915830969810486\n",
      "422 0.04357588291168213\n",
      "423 0.4896980822086334\n",
      "424 0.4213946461677551\n",
      "425 0.36572784185409546\n",
      "426 0.12923529744148254\n",
      "427 0.5229228734970093\n",
      "428 0.770810604095459\n",
      "429 0.4281606078147888\n",
      "430 0.38533082604408264\n",
      "431 0.11228673905134201\n",
      "432 0.12014661729335785\n",
      "433 0.5066710114479065\n",
      "434 0.7154948711395264\n",
      "435 0.08985961973667145\n",
      "436 0.36750471591949463\n",
      "437 1.1001806259155273\n",
      "438 0.4051971733570099\n",
      "439 0.5390541553497314\n",
      "440 0.5732767581939697\n",
      "441 0.5922435522079468\n",
      "442 0.3235422968864441\n",
      "443 0.44330713152885437\n",
      "444 0.7471727132797241\n",
      "445 0.059689927846193314\n",
      "446 0.4242822229862213\n",
      "447 0.5321778655052185\n",
      "448 0.3846743404865265\n",
      "449 0.35506507754325867\n",
      "450 0.5951811671257019\n",
      "451 0.392108678817749\n",
      "452 0.2776542007923126\n",
      "453 0.38296833634376526\n",
      "454 0.3543853759765625\n",
      "455 0.3032042682170868\n",
      "456 0.600007951259613\n",
      "457 0.09429235011339188\n",
      "458 0.12067929655313492\n",
      "459 0.1242501437664032\n",
      "460 0.5893139243125916\n",
      "461 0.0660230815410614\n",
      "462 0.060698505491018295\n",
      "463 0.550687849521637\n",
      "464 0.09530171006917953\n",
      "465 0.38479262590408325\n",
      "466 0.45841214060783386\n",
      "467 0.05762104690074921\n",
      "468 0.03702785074710846\n",
      "469 0.41336342692375183\n",
      "470 0.037233754992485046\n",
      "471 0.40416136384010315\n",
      "472 0.30145713686943054\n",
      "473 0.2435912787914276\n",
      "474 0.0366031713783741\n",
      "475 0.6262885332107544\n",
      "476 0.5373153686523438\n",
      "477 0.2427777498960495\n",
      "478 0.03308669105172157\n",
      "479 0.3338565528392792\n",
      "480 0.31514355540275574\n",
      "481 0.27655255794525146\n",
      "482 0.8703617453575134\n",
      "483 0.3814745843410492\n",
      "484 0.6078171730041504\n",
      "485 0.16124692559242249\n",
      "486 0.5650583505630493\n",
      "487 0.05858604609966278\n",
      "488 0.22299207746982574\n",
      "489 1.0884175300598145\n",
      "490 0.06867428869009018\n",
      "491 0.0734446570277214\n",
      "492 1.1807644367218018\n",
      "493 0.2926284372806549\n",
      "494 0.41581806540489197\n",
      "495 0.5724213123321533\n",
      "496 0.33034783601760864\n",
      "497 0.7273728251457214\n",
      "498 0.06467396765947342\n",
      "499 0.046418000012636185\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(DynamicNet, self).__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "        and reuse the middle_linear Module that many times to compute hidden layer\n",
    "        representations.\n",
    "\n",
    "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "        Python control-flow operators like loops or conditional statements when\n",
    "        defining the forward pass of the model.\n",
    "\n",
    "        Here we also see that it is perfectly safe to reuse the same Module many\n",
    "        times when defining a computational graph. This is a big improvement from Lua\n",
    "        Torch, where each Module could be used only once.\n",
    "        \"\"\"\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9) # <- need to read Goodfellow book on momentum! :Now had some idea.\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
