{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import codecs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def findFiles(path):\n",
    "    \"\"\"\n",
    "    Find files under the given path.\n",
    "    \"\"\"\n",
    "    return glob.glob(path)\n",
    "\n",
    "def unicodeToAscii(s, vocab=string.ascii_letters+\" .,;'\"):\n",
    "    \"\"\"\n",
    "    Turn a unicode string to plain ASCII.\n",
    "    Params:\n",
    "        s: string to be converted\n",
    "        vocab: vocabulary as in unique characters, default to all ascii chars.\n",
    "    \"\"\"\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in vocab\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1109177 characters,80 unique.\n",
      "{'R': 0, 'L': 1, 'h': 2, '7': 3, '0': 4, 'b': 5, 'W': 6, 'B': 7, 'g': 8, '2': 9, '\\n': 10, 'l': 11, 'J': 12, '6': 13, 'c': 14, ' ': 15, '}': 16, '-': 17, 'I': 18, ')': 19, 'z': 20, 'T': 21, 'e': 22, '?': 23, ':': 24, '\\t': 25, '!': 26, 'd': 27, 'q': 28, 'u': 29, 'N': 30, '\"': 31, 'G': 32, '/': 33, 'S': 34, 'A': 35, ';': 36, 'X': 37, 'k': 38, 'D': 39, 'x': 40, ',': 41, 'Y': 42, 'Z': 43, 'w': 44, 'Q': 45, 'P': 46, 'U': 47, 'a': 48, 'H': 49, '_': 50, '8': 51, 'M': 52, 'm': 53, 's': 54, 'O': 55, '9': 56, 'y': 57, 'i': 58, '3': 59, 'K': 60, 'n': 61, 'p': 62, 'j': 63, 'o': 64, 'V': 65, 'f': 66, '4': 67, 'F': 68, 'r': 69, \"'\": 70, '1': 71, '(': 72, 'E': 73, 't': 74, '.': 75, 'v': 76, '5': 77, '^': 78, 'C': 79}\n",
      "{0: 'R', 1: 'L', 2: 'h', 3: '7', 4: '0', 5: 'b', 6: 'W', 7: 'B', 8: 'g', 9: '2', 10: '\\n', 11: 'l', 12: 'J', 13: '6', 14: 'c', 15: ' ', 16: '}', 17: '-', 18: 'I', 19: ')', 20: 'z', 21: 'T', 22: 'e', 23: '?', 24: ':', 25: '\\t', 26: '!', 27: 'd', 28: 'q', 29: 'u', 30: 'N', 31: '\"', 32: 'G', 33: '/', 34: 'S', 35: 'A', 36: ';', 37: 'X', 38: 'k', 39: 'D', 40: 'x', 41: ',', 42: 'Y', 43: 'Z', 44: 'w', 45: 'Q', 46: 'P', 47: 'U', 48: 'a', 49: 'H', 50: '_', 51: '8', 52: 'M', 53: 'm', 54: 's', 55: 'O', 56: '9', 57: 'y', 58: 'i', 59: '3', 60: 'K', 61: 'n', 62: 'p', 63: 'j', 64: 'o', 65: 'V', 66: 'f', 67: '4', 68: 'F', 69: 'r', 70: \"'\", 71: '1', 72: '(', 73: 'E', 74: 't', 75: '.', 76: 'v', 77: '5', 78: '^', 79: 'C'}\n"
     ]
    }
   ],
   "source": [
    "# IO\n",
    "data = codecs.open('../data/potter.txt', 'r', encoding='utf8', errors='ignore').read()\n",
    "predict = codecs.open('../data/output.txt', 'w', encoding='utf8')\n",
    "chars = list(set(data))\n",
    "data_size = len(data) \n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(f'data has {data_size} characters,{vocab_size} unique.')              # data has 1109177 characters,80 unique.\n",
    "\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "print(char_to_ix)\n",
    "print(ix_to_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_size = 256          # size of hidden layer of neurons\n",
    "seq_length = 128           # number of steps to unroll the RNN for\n",
    "learning_rate = 1e-1\n",
    "\n",
    "\n",
    "# model parameters\n",
    "W_xh = torch.randn((hidden_size, vocab_size), requires_grad=True) * 0.01        # weight: input to hidden\n",
    "W_hh = torch.randn(hidden_size, hidden_size, requires_grad=True) * 0.01         # weight: hidden to hidden, notice shape () is omitable\n",
    "W_hy = torch.randn((vocab_size, hidden_size), requires_grad=True) * 0.01        # weight: hidden to output\n",
    "b_h = torch.zeros((hidden_size, 1))                          # hidden bias\n",
    "b_y = torch.zeros((vocab_size, 1))                           # output bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0019,  0.0017,  0.0044,  ...,  0.0145,  0.0024, -0.0053],\n",
       "        [ 0.0154, -0.0002, -0.0034,  ..., -0.0107,  0.0005, -0.0073],\n",
       "        [ 0.0061, -0.0102,  0.0010,  ..., -0.0098,  0.0107,  0.0051],\n",
       "        ...,\n",
       "        [-0.0096, -0.0042, -0.0127,  ..., -0.0002,  0.0093, -0.0048],\n",
       "        [-0.0172,  0.0064, -0.0142,  ..., -0.0070, -0.0138, -0.0123],\n",
       "        [-0.0010, -0.0053, -0.0154,  ..., -0.0102, -0.0125,  0.0027]],\n",
       "       grad_fn=<MulBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_xh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0156,  0.0050,  0.0032,  ...,  0.0063,  0.0030,  0.0075],\n",
       "        [ 0.0003,  0.0083, -0.0093,  ..., -0.0079,  0.0092,  0.0037],\n",
       "        [-0.0024, -0.0006,  0.0108,  ...,  0.0081, -0.0055,  0.0166],\n",
       "        ...,\n",
       "        [ 0.0096,  0.0102,  0.0066,  ...,  0.0172, -0.0019, -0.0017],\n",
       "        [ 0.0101,  0.0013,  0.0171,  ...,  0.0176,  0.0015, -0.0088],\n",
       "        [ 0.0063, -0.0052,  0.0205,  ..., -0.0043, -0.0033, -0.0081]],\n",
       "       grad_fn=<MulBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0021, -0.0024,  0.0006,  ...,  0.0009,  0.0097, -0.0074],\n",
       "        [ 0.0179,  0.0094, -0.0043,  ...,  0.0006, -0.0180, -0.0037],\n",
       "        [ 0.0024, -0.0092,  0.0072,  ...,  0.0006, -0.0011, -0.0085],\n",
       "        ...,\n",
       "        [-0.0060,  0.0025, -0.0125,  ...,  0.0090,  0.0108, -0.0109],\n",
       "        [-0.0109, -0.0011,  0.0039,  ..., -0.0007,  0.0031, -0.0103],\n",
       "        [-0.0046, -0.0138, -0.0120,  ...,  0.0026, -0.0021, -0.0006]],\n",
       "       grad_fn=<MulBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_h.transpose_(0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.copy(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n\n",
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = torch.tensor(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 6, 8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([2,3]).unsqueeze_(0).transpose_(0,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
